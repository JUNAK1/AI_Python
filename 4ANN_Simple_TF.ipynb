{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4ANN_Simple_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wa83JmGxDWH"
      },
      "source": [
        "#Sistema\n",
        "import sys \n",
        "import os\n",
        "#Data Sciencie\n",
        "import pandas as pd\n",
        "#numerico\n",
        "import numpy as np\n",
        "#graficas\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # estilos de plt\n",
        "#ML\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers.core import Dense\n",
        "import sklearn \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcUm7uVzygsr"
      },
      "source": [
        "#Creamos el dataset a medida\n",
        "#Vamos a resolver el problema (clasificacion) de la compuerta XOR (no separabilidad lineal)\n",
        "\n",
        "#4 combinaciones de la compuerta XOR\n",
        "training_data = np.array([[0,0],[0,1],[1,0],[1,1]],\"float32\")\n",
        "target_data = np.array([[0],[1],[1],[0]],\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtauIsTMygqt"
      },
      "source": [
        "#Arquitectura de la ANN (Artificial Neural Network)\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=2, activation='relu'))#primera capa units=16, input=2, activation = relu\n",
        "model.add(Dense(50,  activation='tanh'))#Capa oculta\n",
        "model.add(Dense(1, activation='sigmoid'))#Capa de salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_5kmMbY4rUB"
      },
      "source": [
        "#Hiperpar√°metros para el entrenamiento\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAZGofe66Rgr"
      },
      "source": [
        "#Entrenamiento de la ANN\n",
        "model.fit(training_data, target_data, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mngog4NN8WKH",
        "outputId": "55ffb1a3-b3f8-42ff-d9b9-b8812d302607"
      },
      "source": [
        "#Validacion del modelo\n",
        "#Aqui deberia probarse con los datos de validation\n",
        "#Pero como nuestro ejemplo es solo un XOR, no hicimos el splitting\n",
        "#por lo tanto usamos los mismos datos de entranamiento\n",
        "\n",
        "testing = model.evaluate(training_data,target_data) #Aqui deberia probarse con los datos de validation\n",
        "#print(testing[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9eefccea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 7.8036e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6YJrDJf9ZOk",
        "outputId": "e4338f3d-9765-4918-abf6-7a290bd74757"
      },
      "source": [
        "#Hacer predicciones (inferencia)\n",
        "#Vamos a mirar que nos responde al ANN ante un nuevo caso\n",
        "inference = model.predict(training_data)\n",
        "print(inference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02885452]\n",
            " [0.97245365]\n",
            " [0.9730001 ]\n",
            " [0.02830276]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXuxdSgcLwip"
      },
      "source": [
        "###Guardar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtwlc0z1-2NH"
      },
      "source": [
        "#Guardar nuestro modelo ANN ya pre entrenado.\n",
        "#Serializar el modelo (Preparar los pesos y la arquitectura de la ANN para ser guardados en un formato estandar)\n",
        "model_json = model.to_json()#variable que contiene el model serializado\n",
        "with open (\"model_xor_preentrenado.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)#lo guardamos en JSON\n",
        "\n",
        "#Encapsular en caja negra (h5)\n",
        "model.save_weights(\"modelo_xor_preentrenado_w.h5\")#Proteje propiedad intelectual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg1CFHn6C_Zl",
        "outputId": "fb8a2dc5-67e0-434c-af19-841f7e79db6f"
      },
      "source": [
        "#Abrir/usar modelo pre-entrenado\n",
        "#JSON\n",
        "archivo = open(\"/content/model_xor_preentrenado.json\",\"r\")\n",
        "leer_datos = archivo.read()\n",
        "archivo.close()\n",
        "modelo_importado = model_from_json(leer_datos)\n",
        "print(\"Red nueronal importada\")\n",
        "#Librerias para el cliente\n",
        "#from keras.models import model_from_json\n",
        "\n",
        "#h5 (importar pesos ya entrenados)\n",
        "modelo_importado.load_weights(\"/content/modelo_xor_preentrenado_w.h5\")\n",
        "\n",
        "#Todo en un solo h5 encapsulado\n",
        "model.save(\"ann_completa_xor_con_pesos.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red nueronal importada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b54ygrm2IXby"
      },
      "source": [
        "#Ya esta todo importado, ahora sintetiza\n",
        "modelo_importado.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
        "inferencia_importado = modelo_importado.predict(training_data)\n",
        "print(inferencia_importado)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDfnD6i-IZnR",
        "outputId": "8f1d2355-6490-408e-c9cc-ca11872b1bf9"
      },
      "source": [
        "#Deplegando en el lado del cliente la ANN completa\n",
        "#import numpy as np\n",
        "#import tensorflow as tf\n",
        "#import keras \n",
        "\n",
        "modelo_encapsulado = keras.models.load_model(\"/content/ann_completa_xor_con_pesos.h5\")\n",
        "inferencia_encapsulado = modelo_encapsulado.predict([[0,1]])\n",
        "print(inferencia_encapsulado)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.97245365]]\n"
          ]
        }
      ]
    }
  ]
}